This repository host BentoML example projects showing you how to serve and deploy different open-source Large Language Models using [vLLM](https://vllm.ai), a high-throughput and memory-efficient inference engine. We include the following models:

- [meta-llama/Llama-2-7b-chat-hf](llama2-7b-chat/)
- [Mistral-7B-Instruct-v0.2](mistral-7b-instruct/)
- [Mixtral-8x7B-Instruct-v0.1 with gptq quantization](mistral-7b-instruct/)
